{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opening-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the important library\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unique-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking one paragraph where we can apply bag_of-word\n",
    "paragraph =\"\"\"Sachin Ramesh Tendulkar is  born 24 April 1973) is an Indian former international cricketer who served as \n",
    "                  captain of the Indian national team. He is widely regarded as one of the greatest batsmen in the history of cricket.\n",
    "                  He is the highest run scorer of all time in international cricket, and the only player to have scored one hundred international \n",
    "                  centuries, the first batsman to score a double century in a One Day International (ODI), the holder of the record for the most runs\n",
    "                  in both Test and ODI cricket, and the only player to complete more than 30,000 runs in international cricket.[7] In 2013, he was the \n",
    "                  only Indian cricketer included in an all-time Test World XI named to mark the 150th anniversary of Wisden Cricketers' Almanack.[8][9][10]\n",
    "                  He is affectionately known as Little Master or Master Blaster.[11][12][13][14]\n",
    "                  Tendulkar took up cricket at the age of eleven, made his Test debut on 15 November 1989 against Pakistan in Karachi at the\n",
    "                  age of sixteen, and went on to represent Mumbai domestically and India internationally for close to twenty-four years. \n",
    "                  In 2002, halfway through his career, Wisden Cricketers' Almanack ranked him the second-greatest Test batsman of all time,\n",
    "                  behind Don Bradman, and the second-greatest ODI batsman of all time, behind Viv Richards.[15] Later in his career, \n",
    "                  Tendulkar was a part of the Indian team that won the 2011 World Cup, his first win in six World Cup appearances for India.\n",
    "                  [16] He had previously been named \"Player of the Tournament\" at the 2003 edition of the tournament, held in South Africa.\n",
    "\n",
    "                    Tendulkar received the Arjuna Award in 1994 for his outstanding sporting achievement, \n",
    "                    the Rajiv Gandhi Khel Ratna award in 1997, India's highest sporting honour, and the \n",
    "                    Padma Shri and Padma Vibhushan awards in 1999 and 2008, respectively, India's fourth- and \n",
    "                    second-highest civilian awards.[17] After a few hours of his final match on 16 November 2013, \n",
    "                    the Prime Minister's Office announced the decision to award him the Bharat Ratna, \n",
    "                    India's highest civilian award.[18][19] He is the youngest recipient to date and the first ever sportsperson\n",
    "                    to receive the award.\n",
    "                    He also won the 2010 Sir Garfield Sobers Trophy for cricketer of the year at the ICC awards.\n",
    "                    [22] In 2012, Tendulkar was nominated to the Rajya Sabha, the upper house of the Parliament of India.[23]\n",
    "                    He was also the first sportsperson and the first person without an aviation background to be awarded the honorary\n",
    "                    rank of group captain by the Indian Air Force.[24] In 2012, he was named an Honorary Member of the Order of Australia.[25][26]\n",
    "\n",
    "                    In 2010, Time magazine included Sachin in its annual Time 100 list as one of the\n",
    "                    \"Most Influential People in the World\".[27] In December 2012, Tendulkar announced his \n",
    "                    retirement from ODIs.[28] He retired from Twenty20 cricket in October 2013[29] and subsequently \n",
    "                    retired from all forms of cricket on 16 November 2013 after playing his 200th Test match, against \n",
    "                    the West Indies in Mumbai's Wankhede Stadium.[30] Tendulkar played 664 international cricket matches in \n",
    "                    total, scoring 34,357 runs.[7]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "clear-pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# cretaing object of steamer class\n",
    "ps = PorterStemmer()\n",
    "\n",
    "wordnet = WordNetLemmatizer() #object of WordNetLemmatizer class\n",
    "\n",
    "#tokenizing the senteces \n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "right-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the raw text\n",
    "corpus =[]\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])  # removing all the un necessary word except a-z A-z\n",
    "    review = review.lower() #converting to lowercase\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if word not in set(stopwords.words('english'))]  # using steaming\n",
    "    review =' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cultural-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the raw text\n",
    "corpus1 =[]\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])  # removing all the un necessary word except a-z A-z\n",
    "    review = review.lower() #converting to lowercase\n",
    "    review = review.split()\n",
    "    review = [wordnet.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review =' '.join(review)\n",
    "    corpus1.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dietary-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "clf = TfidfVectorizer()\n",
    "X = clf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "reduced-horror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.41936016, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.22072716, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.36931862, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.41936016, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.33381358, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.41936016, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.41936016, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "communist-thesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rocky-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "clf = TfidfVectorizer()\n",
    "X1 = clf.fit_transform(corpus1).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "orange-array",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.33939595, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.28851756, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.37549473, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.42637312, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.33939595,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.42637312, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.42637312,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-dimension",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
